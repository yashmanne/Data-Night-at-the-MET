{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f2f34da8-93fc-42ae-971b-d08ef8dde3d5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ade3adb-47a7-4bb4-99d6-c5db334c371c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ccf9d2f0-4d5a-48f3-baf3-fe11b92afb4a/lib/python3.9/site-packages (4.65.0)\r\n\u001B[33mWARNING: You are using pip version 21.2.4; however, version 23.1.2 is available.\r\nYou should consider upgrading via the '/local_disk0/.ephemeral_nfs/envs/pythonEnv-ccf9d2f0-4d5a-48f3-baf3-fe11b92afb4a/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c5521d2-1c54-4667-a9c6-b3c84fe9ecce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[11]: <module 'data_cleaning' from '/Workspace/Users/cjault@uw.edu/data_cleaning.py'>"
     ]
    }
   ],
   "source": [
    "import data_cleaning\n",
    "from importlib import reload\n",
    "reload(data_cleaning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02457e0e-a0b8-4141-af0e-60589508ad86",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d0eabe3c3e74848844ef531a1fe804c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/477804 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13e0f8b600a54fdb9a8d82d4c0e06fd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/477804 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "artwork, artist, medium = data_cleaning.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e193098-ec50-42e3-b54d-d3c706b787f1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6290f908-bb27-43da-87f3-9810b6884665",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, BooleanType, ArrayType\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Read Online CSV\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec7ed1be-ffc6-4ba7-abf2-094354cf2156",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "artwork_schema = StructType([\n",
    "    StructField(\"Object ID\", IntegerType(), nullable=False),\n",
    "    StructField(\"Object Name\", StringType(), nullable=True),\n",
    "    StructField(\"Is Highlight\", BooleanType(), nullable=True),\n",
    "    StructField(\"Country\", StringType(), nullable=True),\n",
    "    StructField(\"Period\", StringType(), nullable=True),\n",
    "    StructField(\"Culture\", StringType(), nullable=True),\n",
    "    StructField(\"Gallery Number\", IntegerType(), nullable=True),\n",
    "    StructField(\"Department\", StringType(), nullable=True),\n",
    "    StructField(\"Medium IDs\", ArrayType(IntegerType()), nullable=True),\n",
    "    StructField(\"Artist IDs\", ArrayType(IntegerType()), nullable=True)\n",
    "])\n",
    "\n",
    "artist_schema = StructType([\n",
    "    StructField(\"ID\", IntegerType(), nullable=False),\n",
    "    StructField(\"Name\", StringType(), nullable=True),\n",
    "    StructField(\"Gender\", StringType(), nullable=True)\n",
    "])\n",
    "medium_schema = StructType([\n",
    "    StructField(\"ID\", IntegerType(), nullable=False),\n",
    "    StructField(\"Material\", StringType(), nullable=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93f06f04-b75b-4e11-9229-31cf748333c6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "artwork = artwork[['Object ID', 'Object Name', 'Is Highlight', 'Country', 'Period', 'Culture', 'Gallery Number', 'Department', 'Medium IDs', 'Artist IDs']]\n",
    "medium = medium[['ID', 'Material']]\n",
    "artist = artist[['ID', 'Name', 'Gender']]\n",
    "\n",
    "# deal with missing values so pyspark can read them\n",
    "n_artwork = artwork.copy()\n",
    "n_artwork['Gallery Number'] = artwork['Gallery Number'].fillna(np.nan).replace([np.nan], [None])\n",
    "n_artwork['Artist IDs'] = artwork['Artist IDs'].fillna(np.nan).replace([np.nan],[None])\n",
    "n_artwork['Medium IDs'] = artwork['Medium IDs'].fillna(np.nan).replace([np.nan],[None])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47b48f91-eef3-478f-9b09-780564d63973",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create PySpark Tables\n",
    "df_artwork = spark.createDataFrame(data=n_artwork, schema=artwork_schema)\n",
    "df_artist = spark.createDataFrame(data=artist, schema=artist_schema)\n",
    "df_medium = spark.createDataFrame(data=medium, schema=medium_schema)\n",
    "\n",
    "df_artwork.createOrReplaceTempView(\"artwork\")\n",
    "df_medium.createOrReplaceTempView(\"medium\")\n",
    "df_artist.createOrReplaceTempView('artist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b68e57a-80a3-4bce-bf05-ed80385db30f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Query 1\n",
    "Are certain types of artworks highlighted more than others? Specifically, are artworks in certain galleries/departments highlighted more than others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bbf10bc-18a8-4ac9-a5e9-2c0b569fa089",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+----------------+\n|          Department|Gallery Number|HighlightedCount|\n+--------------------+--------------+----------------+\n|       The Libraries|          null|             347|\n|   Costume Institute|          null|             134|\n|   The American Wing|          null|             127|\n|Modern and Contem...|          null|             125|\n|         Photographs|          null|             112|\n|Arts of Africa, O...|          null|              92|\n| Drawings and Prints|          null|              87|\n|         Islamic Art|          null|              52|\n| Musical Instruments|           684|              52|\n|Robert Lehman Col...|          null|              41|\n|           Asian Art|          null|              31|\n|   The American Wing|           706|              27|\n|       The Libraries|          1004|              27|\n| Musical Instruments|          null|              26|\n|   The American Wing|           746|              25|\n| Musical Instruments|           681|              22|\n|Ancient Near East...|           403|              21|\n|  European Paintings|          null|              20|\n|        Medieval Art|           304|              18|\n|Ancient Near East...|          null|              18|\n+--------------------+--------------+----------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "query1 = \"\"\"\n",
    "SELECT  Department, `Gallery Number`, COUNT(*) AS HighlightedCount\n",
    "FROM artwork\n",
    "WHERE `Is Highlight` = True\n",
    "GROUP BY Department, `Gallery Number`\n",
    "ORDER BY HighlightedCount DESC\n",
    "\"\"\"\n",
    "\n",
    "result1 = spark.sql(query1)\n",
    "result1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc486eb5-695a-451e-bb49-3df68394c675",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+\n|          Department|HighlightedCount|\n+--------------------+----------------+\n|   The American Wing|             434|\n|       The Libraries|             376|\n|Modern and Contem...|             179|\n|   Costume Institute|             134|\n|  European Paintings|             125|\n|         Islamic Art|             120|\n| Greek and Roman Art|             115|\n|        Egyptian Art|             114|\n|         Photographs|             113|\n| Musical Instruments|             105|\n|Arts of Africa, O...|             104|\n|Robert Lehman Col...|              98|\n| Drawings and Prints|              89|\n|European Sculptur...|              82|\n|Ancient Near East...|              75|\n|       The Cloisters|              58|\n|           Asian Art|              55|\n|      Arms and Armor|              54|\n|        Medieval Art|              54|\n+--------------------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "query1a = \"\"\"\n",
    "SELECT  Department, COUNT(*) AS HighlightedCount\n",
    "FROM artwork\n",
    "WHERE `Is Highlight` = True\n",
    "GROUP BY Department\n",
    "ORDER BY HighlightedCount DESC\n",
    "\"\"\"\n",
    "\n",
    "result1a = spark.sql(query1a)\n",
    "result1a.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec29ba5c-cea8-47d5-ad2e-2c9a16597c99",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------+\n|Gallery Number|HighlightedCount|\n+--------------+----------------+\n|           684|              53|\n|           706|              27|\n|          1004|              27|\n|           746|              25|\n|           681|              22|\n|           403|              22|\n|           304|              19|\n|           743|              15|\n|            14|              15|\n|           119|              14|\n|           704|              13|\n|           762|              12|\n|           153|              12|\n|           136|              12|\n|           405|              12|\n|           700|              11|\n|           162|              11|\n|           964|              11|\n|           121|              11|\n|           373|              11|\n+--------------+----------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "query1b = \"\"\"\n",
    "SELECT  `Gallery Number`, COUNT(*) AS HighlightedCount\n",
    "FROM artwork\n",
    "WHERE `Is Highlight` = True AND `Gallery Number` IS NOT NULL\n",
    "GROUP BY `Gallery Number`\n",
    "ORDER BY HighlightedCount DESC\n",
    "\"\"\"\n",
    "\n",
    "result1b = spark.sql(query1b)\n",
    "result1b.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3707a77a-e2eb-4709-949a-9729395f2346",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Question 2\n",
    "Whose artwork has been acquired most by the museum? What about by period, gender, culture, medium, department, and country?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f2c9e09-fccc-423d-9648-c4aa6ed98666",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n Artist\n+--------------------+-----+\n|                Name|Count|\n+--------------------+-----+\n|        Walker Evans| 7668|\n| W. Duke, Sons & Co.| 5615|\n|             Unknown| 4479|\n|Kinney Brothers T...| 4449|\n|      Allen & Ginter| 4314|\n|American Tobacco ...| 3275|\n|      Brewster & Co.| 3146|\n|   Thomas Rowlandson| 2969|\n|   Goodwin & Company| 2778|\n|      Jacques Callot| 2366|\n+--------------------+-----+\n\n\n Gender\n+------+------+\n|Gender| Count|\n+------+------+\n|  Male|404164|\n|Female| 14556|\n+------+------+\n\n\n Period\n+--------------------+-----+\n|              Period|Count|\n+--------------------+-----+\n|         New Kingdom|12043|\n|          Edo period| 9125|\n|             Archaic| 8166|\n|           Classical| 6979|\n|        Qing dynasty| 6491|\n|      Middle Kingdom| 4687|\n|   Archaic/Classical| 2166|\n|         Late Period| 1820|\n|      Early Imperial| 1523|\n|Third Intermediat...| 1357|\n+--------------------+-----+\n\n\n Department\n+--------------------+------+\n|          Department| Count|\n+--------------------+------+\n| Drawings and Prints|167152|\n|European Sculptur...| 42934|\n|         Photographs| 37192|\n|           Asian Art| 36817|\n| Greek and Roman Art| 33750|\n|   Costume Institute| 31412|\n|        Egyptian Art| 27962|\n|   The American Wing| 18412|\n|         Islamic Art| 15473|\n|Modern and Contem...| 14241|\n+--------------------+------+\n\n\n Culture\n+--------+-----+\n| Culture|Count|\n+--------+-----+\n|American|29159|\n|  French|23817|\n|   Greek|20697|\n|   Japan|16880|\n| Chinese|15904|\n| British|10855|\n| Italian|10807|\n|  German| 7817|\n|Japanese| 6102|\n|   Roman| 5466|\n+--------+-----+\n\n\n Country\n+---------------+-----+\n|        Country|Count|\n+---------------+-----+\n|          Egypt|31446|\n|  United States| 9590|\n|           Iran| 6595|\n|           Peru| 3427|\n|         France| 1966|\n|Byzantine Egypt| 1673|\n|         Mexico| 1563|\n|          India| 1416|\n|      Indonesia| 1391|\n|        England| 1256|\n+---------------+-----+\n\n\n Medium\n+--------------------+-----+\n|            Material|Count|\n+--------------------+-----+\n|             etching|26738|\n|                silk|25881|\n|          terracotta|23697|\n|commercial color ...|18343|\n|           engraving|15083|\n|                wood|12359|\n|                gold|12078|\n|               glass|10795|\n|              cotton|10755|\n|              silver|10592|\n+--------------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "\n",
    "# Register the exploded DataFrame as a SQL temporary view\n",
    "exploded_df = df_artwork.select(\"Object ID\", \"Period\", 'Department', 'Culture', 'Country', explode(\"Artist IDs\").alias(\"ArtistID\"))\n",
    "\n",
    "exploded_df.createOrReplaceTempView(\"artwork_exp\")\n",
    "\n",
    "print('\\n Artist')\n",
    "query1 = \"\"\"\n",
    "    SELECT \n",
    "        artist.Name, \n",
    "        COUNT(artwork_exp.`Object ID`) AS Count \n",
    "    FROM \n",
    "        artwork_exp \n",
    "    JOIN \n",
    "        artist ON artist.ID = artwork_exp.ArtistID \n",
    "    GROUP BY \n",
    "        artist.Name \n",
    "    ORDER BY \n",
    "        COUNT(artwork_exp.`Object ID`) DESC \n",
    "    LIMIT 10\n",
    "\"\"\"\n",
    "result = spark.sql(query1)\n",
    "result.show()\n",
    "\n",
    "print('\\n Gender')\n",
    "query2 = \"\"\"\n",
    "    SELECT \n",
    "        artist.Gender, \n",
    "        COUNT(artwork_exp.`Object ID`) AS Count \n",
    "    FROM \n",
    "        artwork_exp \n",
    "    JOIN \n",
    "        artist ON artist.ID = artwork_exp.ArtistID \n",
    "    GROUP BY \n",
    "        artist.Gender \n",
    "    ORDER BY \n",
    "        COUNT(artwork_exp.`Object ID`) DESC \n",
    "    LIMIT 10\n",
    "\"\"\"\n",
    "result = spark.sql(query2)\n",
    "result.show()\n",
    "\n",
    "print('\\n Period')\n",
    "query3 = \"\"\"\n",
    "    SELECT \n",
    "        artwork.Period, \n",
    "        COUNT(artwork.`Object ID`) AS Count \n",
    "    FROM \n",
    "        artwork \n",
    "    WHERE \n",
    "        artwork.Period IS NOT NULL \n",
    "    GROUP BY \n",
    "        artwork.Period \n",
    "    ORDER BY \n",
    "        COUNT(artwork.`Object ID`) DESC \n",
    "    LIMIT 10\n",
    "\"\"\"\n",
    "result = spark.sql(query3)\n",
    "result.show()\n",
    "\n",
    "print('\\n Department')\n",
    "query4 = \"\"\"\n",
    "    SELECT \n",
    "        artwork.Department, \n",
    "        COUNT(artwork.`Object ID`) AS Count \n",
    "    FROM \n",
    "        artwork \n",
    "    GROUP BY \n",
    "        artwork.Department \n",
    "    ORDER BY \n",
    "        COUNT(artwork.`Object ID`) DESC \n",
    "    LIMIT 10\n",
    "\"\"\"\n",
    "result = spark.sql(query4)\n",
    "result.show()\n",
    "\n",
    "print('\\n Culture')\n",
    "query5 = \"\"\"\n",
    "    SELECT \n",
    "        artwork.Culture, \n",
    "        COUNT(artwork.`Object ID`) AS Count \n",
    "    FROM \n",
    "        artwork \n",
    "    WHERE \n",
    "        artwork.Culture IS NOT NULL \n",
    "    GROUP BY \n",
    "        artwork.Culture \n",
    "    ORDER BY \n",
    "        COUNT(artwork.`Object ID`) DESC \n",
    "    LIMIT 10\n",
    "\"\"\"\n",
    "result = spark.sql(query5)\n",
    "result.show()\n",
    "\n",
    "print('\\n Country')\n",
    "query6 = \"\"\"\n",
    "    SELECT \n",
    "        artwork.Country, \n",
    "        COUNT(artwork.`Object ID`) AS Count \n",
    "    FROM \n",
    "        artwork \n",
    "    WHERE \n",
    "        artwork.Country IS NOT NULL \n",
    "    GROUP BY \n",
    "        artwork.Country \n",
    "    ORDER BY \n",
    "        COUNT(artwork.`Object ID`) DESC \n",
    "    LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "result = spark.sql(query6)\n",
    "\n",
    "result.show()\n",
    "\n",
    "\n",
    "print('\\n Medium')\n",
    "\n",
    "exploded_df = df_artwork.select(\"Object ID\", explode(\"Medium IDs\").alias(\"MediumID\"))\n",
    "\n",
    "exploded_df.createOrReplaceTempView(\"artwork_exp\")\n",
    "\n",
    "query7 = \"\"\"\n",
    "SELECT \n",
    "    medium.material as Material, count(`Object ID`) AS Count \n",
    "FROM \n",
    "    artwork_exp \n",
    "JOIN \n",
    "    medium ON medium.ID  = artwork_exp.`MediumID` \n",
    "GROUP BY \n",
    "    medium.material \n",
    "ORDER BY \n",
    "    count(`Object ID`) DESC LIMIT 10\"\"\"\n",
    "result = spark.sql(query7)\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "43a74bf9-9a9f-4d8f-9f26-217c5c81e20c",
     "showTitle": true,
     "title": ""
    }
   },
   "source": [
    "## Question 3\n",
    "What is the distribution of the number of artists per artwork?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e996dfd2-4a55-427d-8b64-b1ecd4a33163",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+\n|TeamSize|       Ratio|\n+--------+------------+\n| unknown|0.4254589748|\n|       1|0.3906727445|\n|       2|0.1185360524|\n|       3|0.0443445430|\n|       4|0.0121723552|\n|       5|0.0038593231|\n|       6|0.0014461997|\n|       7|0.0014252706|\n|       8|0.0005734569|\n|       9|0.0002532419|\n|      10|0.0002260341|\n|      11|0.0001276674|\n|      12|0.0001381320|\n|      13|0.0001067383|\n|      14|0.0000732518|\n|      15|0.0000753447|\n|      16|0.0000523227|\n|      17|0.0000334865|\n|      18|0.0000586014|\n|      19|0.0000355794|\n+--------+------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import size\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT \n",
    "        CASE WHEN size(artwork.`Artist IDs`) = -1 THEN 'unknown' ELSE CAST(size(artwork.`Artist IDs`) AS STRING) END as TeamSize,\n",
    "        CAST(COUNT(artwork.`Object ID`) / (SELECT COUNT(*) FROM artwork) AS DECIMAL(10, 10)) as Ratio\n",
    "    FROM \n",
    "        artwork\n",
    "    GROUP BY \n",
    "        size(artwork.`Artist IDs`)\n",
    "    ORDER BY \n",
    "        size(artwork.`Artist IDs`)\n",
    "\"\"\"\n",
    "result = spark.sql(query)\n",
    "\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38be373e-adca-48bc-94e6-db475826485c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Question 4\n",
    "Are there any artworks with the same title?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28c3b709-d15f-41d8-bc7f-d30d1d5b4ccd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n|   Object Name|Count|\n+--------------+-----+\n|         Print|99439|\n|    Photograph|28458|\n|       Drawing|25788|\n|          Book|13393|\n|      Fragment| 9566|\n|Kylix fragment| 8927|\n|         Piece| 8630|\n|      Painting| 5932|\n|      Negative| 5928|\n|          Bowl| 3617|\n+--------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    artwork.`Object Name`, COUNT(artwork.`Object ID`) as Count \n",
    "FROM \n",
    "    artwork  \n",
    "GROUP BY  \n",
    "    artwork.`Object Name` \n",
    "ORDER BY \n",
    "    COUNT(artwork.`Object ID`) \n",
    "DESC LIMIT 10\n",
    "\"\"\"\n",
    "result = spark.sql(query)\n",
    "\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "899afc5d-5277-4bbd-90b7-95bba80f1412",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Query 5\n",
    "Of the ten countries from which art is most frequently acquired, which artists are most common?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39996597-68cb-4bf6-a56d-f759e98caf79",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n|             Country|ArtworkCount|\n+--------------------+------------+\n|               Egypt|       31446|\n|       United States|        9590|\n|                Iran|        6595|\n|                Peru|        3427|\n|              France|        1966|\n|     Byzantine Egypt|        1673|\n|              Mexico|        1563|\n|               India|        1416|\n|           Indonesia|        1391|\n|             England|        1256|\n|               China|         938|\n|              Turkey|         921|\n|             Germany|         900|\n|    Papua New Guinea|         881|\n|             Nigeria|         647|\n|               Italy|         546|\n|               Syria|         528|\n|Democratic Republ...|         507|\n|               Spain|         432|\n|                Iraq|         427|\n+--------------------+------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Query 5 needs Query 1 to run so putting it here \n",
    "\n",
    "query1 = \"\"\"\n",
    "SELECT Country, COUNT(*) AS ArtworkCount\n",
    "FROM artwork\n",
    "WHERE Country IS NOT NULL\n",
    "GROUP BY Country\n",
    "ORDER BY ArtworkCount DESC\n",
    "\"\"\"\n",
    "\n",
    "result1 = spark.sql(query1)\n",
    "result1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7acbf776-7118-450d-9242-f3ffd5a6592a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n|          ArtistName|ArtworkCount|\n+--------------------+------------+\n|Louis Comfort Tif...|         621|\n|     Tiffany Studios|         537|\n|Tiffany Glass and...|         364|\n|Tiffany Glass Com...|         199|\n|Union Porcelain W...|         184|\n|Abu'l Qasim Firdausi|         162|\n|Nina de Garis Davies|         155|\n|Boston & Sandwich...|         147|\n|      Walter Tyndale|         134|\n|       Tiffany & Co.|         131|\n+--------------------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "df_artwork_exploded = df_artwork.withColumn(\"Artist IDs\", explode(df_artwork['Artist IDs']))\n",
    "\n",
    "result1.createOrReplaceTempView(\"result1\")\n",
    "df_artwork_exploded.createOrReplaceTempView(\"artwork_exploded\")\n",
    "\n",
    "query5 = \"\"\"\n",
    "SELECT artist.Name as ArtistName, TopArtists.ArtworkCount FROM \n",
    "(SELECT `Artist IDs` as `Artist ID`, COUNT(*) as ArtworkCount FROM artwork_exploded\n",
    "WHERE Country IN (SELECT Country FROM result1 ORDER BY ArtworkCount DESC LIMIT 5)\n",
    "GROUP BY `Artist IDs`\n",
    "ORDER BY ArtworkCount DESC\n",
    "LIMIT 10) as TopArtists, artist\n",
    "WHERE TopArtists.`Artist ID` = artist.ID\n",
    "ORDER BY TopArtists.ArtworkCount DESC\n",
    "\"\"\"\n",
    "\n",
    "result5 = spark.sql(query5)\n",
    "result5.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5a65d628-6199-4ca2-bd06-2dbddf185bae",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Query 6\n",
    "Are artworks from specific time periods more likely to be highlighted (displayed) than others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bb577f1-a6d9-4c8c-9552-599de4d994b5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n|              Period|PercentHighlighted|\n+--------------------+------------------+\n|      Timurid period|             100.0|\n|Late Early Cyclad...|             100.0|\n|  Parthian or Kushan|             100.0|\n|     Final Neolithic|             100.0|\n|      Pandyan period|             100.0|\n|      Solanki period|             100.0|\n|Shang dynastyâ€“Wes...|             100.0|\n|Third Intermediat...|             100.0|\n|Early Tokugawa pe...|             100.0|\n|            Tokugawa|             100.0|\n|Late Period or Ea...|             100.0|\n|early Ptolemaic P...|             100.0|\n|  Hellenistic period|              50.0|\n|  Late Helladic IIIC|              50.0|\n|early Eastern Jav...|              50.0|\n|late Anuradhapura...|              50.0|\n|        Ming Dynasty|              40.0|\n|Early Cycladic II...| 33.33333333333333|\n|             Severan| 28.57142857142857|\n|            Augustan|              25.0|\n+--------------------+------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "query6 = \"\"\"\n",
    "SELECT Period, \n",
    "  (SUM(CASE WHEN `Is Highlight` = TRUE THEN 1 ELSE 0 END) / COUNT(*)) * 100  AS PercentHighlighted\n",
    "FROM artwork\n",
    "WHERE Period IS NOT NULL\n",
    "GROUP BY Period\n",
    "ORDER BY PercentHighlighted DESC\n",
    "\"\"\"\n",
    "\n",
    "result6 = spark.sql(query6)\n",
    "result6.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1611d2cc-02d2-46c2-bf4d-040dcb25de82",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Logistic Regression\n",
    "Predict the possibility of being highlighted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b0064df-b8a1-455a-945c-31f66a91da04",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Transformer\n",
    "from pyspark.ml.param import Param, Params\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol\n",
    "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, IntegerType\n",
    "\n",
    "class MultiHotEncoder(Transformer, HasInputCol, HasOutputCol, DefaultParamsReadable, DefaultParamsWritable):\n",
    "    def __init__(self, inputCol=None, outputCol=None):\n",
    "        super(MultiHotEncoder, self).__init__()\n",
    "        self._setDefault(inputCol=None, outputCol=None)\n",
    "        self._set(inputCol=inputCol, outputCol=outputCol)\n",
    "\n",
    "    def setInputCol(self, value):\n",
    "        return self._set(inputCol=value)\n",
    "\n",
    "    def getInputCol(self):\n",
    "        return self.getOrDefault(self.inputCol)\n",
    "\n",
    "    def setOutputCol(self, value):\n",
    "        return self._set(outputCol=value)\n",
    "\n",
    "    def getOutputCol(self):\n",
    "        return self.getOrDefault(self.outputCol)\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        input_col = self.getInputCol()\n",
    "        output_col = self.getOutputCol()\n",
    "\n",
    "        def multi_hot_encode(arr):\n",
    "            unique_values = set(arr)\n",
    "            return [1 if val in unique_values else 0 for val in range(max(unique_values) + 1)]\n",
    "\n",
    "        multi_hot_encode_udf = udf(multi_hot_encode, ArrayType(IntegerType()))\n",
    "\n",
    "        return dataset.withColumn(output_col, multi_hot_encode_udf(input_col))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81badf02-269e-4269-a4b2-3a83f3c6e81c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+\n|Is Highlight_numeric|prediction|         probability|\n+--------------------+----------+--------------------+\n|                   0|       0.0|[0.99999999158770...|\n|                   1|       1.0|[7.07114400554553...|\n|                   0|       0.0|[0.99999999242119...|\n|                   0|       0.0|[0.99999999158770...|\n+--------------------+----------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col\n",
    "# Create a StringIndexer for each categorical column\n",
    "artwork_df = df_artwork.withColumn(\"Is Highlight_numeric\", col(\"Is Highlight\").cast(\"integer\"))\n",
    "artwork_df = artwork_df.dropna()\n",
    "indexers = [\n",
    "    StringIndexer(inputCol=col, outputCol=col+\"_index\", handleInvalid=\"keep\")\n",
    "    for col in [\"Country\", \"Period\", \"Culture\", \"Department\"]\n",
    "]\n",
    "\n",
    "# Create a OneHotEncoder for each indexed categorical column\n",
    "encoders = [\n",
    "    OneHotEncoder(inputCol=col+\"_index\", outputCol=col+\"_encoded\")\n",
    "    for col in [\"Country\", \"Period\", \"Culture\", \"Department\"]\n",
    "]\n",
    "\n",
    "# Create a MultiHotEncoder for the MediumIDs column\n",
    "# medium_encoder = MultiHotEncoder(inputCol=\"Medium IDs\", outputCol=\"Medium IDs_encoded\")\n",
    " \n",
    "# Create a MultiHotEncoder for the ArtistIDs column\n",
    "# artist_encoder = MultiHotEncoder(inputCol=\"Artist IDs\", outputCol=\"Artist IDs_encoded\")\n",
    "\n",
    "# Create a VectorAssembler to combine all features into a single vector column\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"Gallery Number\"\n",
    "    # , \"Medium IDs_encoded\", \"Artist IDs_encoded\"\n",
    "    ] + [col+\"_encoded\" for col in [\"Country\", \"Period\", \"Culture\", \"Department\"]],\n",
    "    outputCol=\"features\",\n",
    "    handleInvalid=\"skip\"\n",
    ")\n",
    "\n",
    "# Create a LogisticRegression classifier\n",
    "logistic_regression = LogisticRegression(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"Is Highlight_numeric\"\n",
    ")\n",
    "\n",
    "# Create a pipeline to assemble and transform the features and train the logistic regression model\n",
    "pipeline = Pipeline(stages=indexers + encoders + [\n",
    "    # medium_encoder, artist_encoder,\n",
    "     assembler, logistic_regression])\n",
    "\n",
    "# Fit the pipeline to the artwork DataFrame\n",
    "model = pipeline.fit(artwork_df)\n",
    "\n",
    "# Perform predictions on the artwork DataFrame\n",
    "predictions = model.transform(artwork_df)\n",
    "\n",
    "# Show the predicted labels and probabilities\n",
    "predictions.select(\"Is Highlight_numeric\", \"prediction\", \"probability\").show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "FinalQueries",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
