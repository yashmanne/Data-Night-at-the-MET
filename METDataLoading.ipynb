{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bb5cf8d-d153-4dc1-9035-3c7fa36b1577",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Read Online CSV\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Define the URL of the CSV file\n",
    "csv_url = \"https://media.githubusercontent.com/media/metmuseum/openaccess/master/MetObjects.csv\"\n",
    "\n",
    "# Download the CSV file using pandas and create a Pandas DataFrame\n",
    "df = pd.read_csv(csv_url,low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19b15ef1-845b-4adb-94cd-f9e0cdf3f72d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define function to split by '|' and return unique countries\n",
    "def get_unique_values(row):\n",
    "    values = []\n",
    "    if row == 'nan':\n",
    "        return [None]\n",
    "    for v in row.split('|'):\n",
    "        if v.strip():\n",
    "            values.append(v.strip())\n",
    "            if v.strip() == 'nan':\n",
    "                values.append(None)\n",
    "        else: \n",
    "            values.append(None)\n",
    "    # if len(list(values)) > 0:\n",
    "    #     return list(values)\n",
    "    return values\n",
    "\n",
    "df_pandas = df.copy()\n",
    "\n",
    "df_pandas['Artist Role'] = df_pandas['Artist Role'].astype(str)\n",
    "df_pandas['Artist Role'] = df_pandas['Artist Role'].apply(get_unique_values)\n",
    "\n",
    "df_pandas['Artist Display Name'] = df_pandas['Artist Display Name'].astype(str)\n",
    "df_pandas['Artist Display Name'] = df_pandas['Artist Display Name'].apply(get_unique_values)\n",
    "\n",
    "df_pandas['Artist Gender'] = df_pandas['Artist Gender'].astype(str)\n",
    "df_pandas['Artist Gender'] = df_pandas['Artist Gender'].apply(get_unique_values)\n",
    "\n",
    "df_pandas = df_pandas.replace('nan', None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0376f29-21e8-4490-b8e6-ed5fa90ef5ef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcdff1ea-7cd4-48ba-9974-16f3f40ad6f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Medium Table\n",
    "medium = {'Material': df_pandas['Medium'].unique(), 'ID': list(range(len(df_pandas['Medium'].unique())))}\n",
    "df_medium_pd = pd.DataFrame(medium)\n",
    "df_medium = spark.createDataFrame(df_medium_pd)\n",
    "\n",
    "# Artist Table\n",
    "df_exploded_name = df_pandas.explode('Artist Display Name')\n",
    "df_exploded_gender = df_pandas.explode('Artist Gender')\n",
    "df_exploded_name['Gender'] = df_exploded_gender['Artist Gender']\n",
    "df_exploded_name.loc[(df_exploded_name['Gender'] != 'Female'), 'Gender'] = 'Male'\n",
    "df_exploded_name.loc[(df_exploded_name['Artist Display Name'].isnull()), 'Gender'] = None\n",
    "df_artist_pd = df_exploded_name[['Gender', 'Artist Display Name']]\n",
    "df_artist_pd = df_artist_pd.drop_duplicates(subset=['Artist Display Name'])\n",
    "df_artist_pd = df_artist_pd.dropna()\n",
    "df_artist_pd.loc[:,'ID'] = list(range(df_artist_pd.shape[0]))\n",
    "df_artist = spark.createDataFrame(df_artist_pd)\n",
    "\n",
    "# Create Table\n",
    "df = df_pandas.explode('Artist Display Name')\n",
    "df = df[['Artist Display Name', 'Object ID']]\n",
    "df = df.dropna()\n",
    "df_creates_pd = pd.merge(df, df_artist_pd, on='Artist Display Name', how='left')\n",
    "df_creates_pd.drop(['Artist Display Name', 'Gender'], axis=1, inplace=True)\n",
    "df_creates_pd = df_creates_pd.rename(columns={'ID': 'Artist ID'})\n",
    "df_creates = spark.createDataFrame(df_creates_pd)\n",
    "\n",
    "# Artwork Table\n",
    "df = df_pandas[['Object ID', 'Gallery Number', 'Medium', 'Department', 'Culture', 'Period', 'Country', 'Is Highlight', 'Artist Display Name']]\n",
    "df_artwork_pd = pd.merge(df, df_medium_pd, left_on='Medium', right_on='Material')\n",
    "df_artwork_pd.drop(['Material', 'Medium'], axis=1, inplace=True)\n",
    "df_artwork_pd = df_artwork_pd.rename(columns={'ID': 'MaterialID'})\n",
    "df_artwork = spark.createDataFrame(df_artwork_pd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b5d26d8-b84e-46fc-aff8-06524f1415ea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- Object ID: long (nullable = true)\n |-- Gallery Number: string (nullable = true)\n |-- Department: string (nullable = true)\n |-- Culture: string (nullable = true)\n |-- Period: string (nullable = true)\n |-- Country: string (nullable = true)\n |-- Is Highlight: boolean (nullable = true)\n |-- Artist Display Name: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- MaterialID: long (nullable = true)\n\nNone\nroot\n |-- Material: string (nullable = true)\n |-- ID: long (nullable = true)\n\nNone\n"
     ]
    }
   ],
   "source": [
    "print(df_artwork.printSchema())\n",
    "print(df_medium.printSchema())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0628aec6-d0ba-4227-8265-eb7402fc28d2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- Gender: string (nullable = true)\n |-- Artist Display Name: string (nullable = true)\n |-- ID: long (nullable = true)\n\nNone\nroot\n |-- Object ID: long (nullable = true)\n |-- Artist ID: long (nullable = true)\n\nNone\n"
     ]
    }
   ],
   "source": [
    "print(df_artist.printSchema())\n",
    "print(df_creates.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d50b4af-b629-4aab-a49b-66b2b60c5414",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+\n|            material|count(Object ID)|\n+--------------------+----------------+\n|          Terracotta|           23532|\n|Commercial color ...|           17548|\n|             Etching|           16851|\n|           Engraving|           11433|\n|Gelatin silver print|           10340|\n|  Albumen photograph|            9653|\n|                Silk|            8495|\n|              Bronze|            7217|\n|                null|            7120|\n|               Glass|            6523|\n+--------------------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Register the DataFrame as a SQL temporary view\n",
    "df_artwork.createOrReplaceTempView(\"artwork\")\n",
    "df_medium.createOrReplaceTempView(\"medium\")\n",
    "\n",
    "# Run a SQL query on the DataFrame\n",
    "result = spark.sql(\"SELECT medium.material, count(`Object ID`) FROM artwork JOIN medium ON medium.ID = artwork.MaterialID GROUP BY medium.material ORDER BY count(`Object ID`) DESC LIMIT 10\")\n",
    "\n",
    "# Show the result of the SQL query\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "835235e9-d973-44dc-b484-43a0baf8c466",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_spark.write.mode(\"overwrite\").saveAsTable(\"METObjects\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92ad2682-6331-48b3-9209-baa104fdad2d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.rdd.RDD'>\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "conf = SparkConf().setAppName(\"LoadData\")\n",
    "sc = SparkContext.getOrCreate(conf)\n",
    "rdd = sc.parallelize(df_pandas.to_dict(\"records\"))\n",
    "print(type(rdd))\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "METDataLoading",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
